<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="generator" content="Hugo 0.53" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>k317h | A Blog to Record My Progress...</title>
    <meta property="og:title" content="k317h | A Blog to Record My Progress...">
    <meta property="og:type" content="website">
    <meta name="Keywords" content="Java,Web,Software">
    <meta name="description" content="Focusing on personal improvement">
    <meta property="og:url" content="https://keithzeng.github.io/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href="/css/normalize.css">
    
    <link rel="stylesheet" href="/css/style.css">
    <link rel="alternate" type="application/rss+xml+xml" href="https://keithzeng.github.io/index.xml" title="k317h" />
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>

    


    
    
</head>


<body>
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <h1>
                        <a id="logo" href="https://keithzeng.github.io">
                            k317h
                        </a>
                    </h1>
                
                <p class="description">A Blog to Record My Progress...</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://keithzeng.github.io">Main</a>
                    
                    <a  href="https://keithzeng.github.io/books/" title="Books">Books</a>
                    
                    <a  href="https://keithzeng.github.io/archives/" title="Archives">Archives</a>
                    
                    <a  href="https://keithzeng.github.io/about/" title="About">About</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>


<div id="body">
    <div class="container">
        <div class="col-group">

            <div class="col-8" id="main">
                <div class="res-cons">
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/convex-optimization/" title="Convex Optimization" >Convex Optimization</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/2/6
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Gradient &amp;&amp; Hessian The gradient of a f, d x 1, can be represented as follow $$ \nabla f(x) = \begin{bmatrix} \frac {\partial f(x)} {\partial x_1} \newline &hellip;\newline \frac {\partial f(x)} {\partial x_d} \end{bmatrix} $$
and the Hessian, d x d, can be represented as
$$ \nabla^2 f(x) = \begin{bmatrix} \frac {\partial^2 f(x)} {\partial x_1^2} &amp; \frac {\partial^2 f(x)} {\partial x_1x_2} &amp; \frac {\partial^2 f(x)} {\partial x_1x_d} \newline &hellip; &amp; &hellip; &amp; &hellip;\newline \frac {\partial^2 f(x)} {\partial x_d^2} &amp; \frac {\partial^2 f(x)} {\partial x_dx_2} &amp; \frac {\partial^2 f(x)} {\partial x_dx_d} \newline \end{bmatrix} $$……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/convex-optimization/">Read More</a></p>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/logistic-regression/" title="Logistic Regression" >Logistic Regression</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/2/1
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Uncertainty in Prediction Related to Linear Regression.
The available features x do not contain enough information to perfectly predict y, such as
 x = medical record for patients at risk for a disease y = will he contact disease in next 5 years  Model We still going to use linear model for conditional probability estmation
$$w_1x_1 + w_2x_2 + &hellip; + w_dx_d + b = w \cdot x + b$$……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/logistic-regression/">Read More</a></p>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/matrix/" title="Matrix" >Matrix</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/2/1
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/mathematic">mathematic</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Determinant Calculation Determinant of 2x2 matrix
$$ A= \begin{bmatrix} a &amp; b \newline c &amp; d \end{bmatrix} $$
$|A| = det(A) = ad -bc$
Determinant of 3x3 matrix, also called expansion of the determinant by first row. Link.
$$ B= \begin{bmatrix} a &amp; b &amp; c \newline d &amp; e &amp; f \newline g &amp; h &amp; k \end{bmatrix} $$
$|B| = det(B) = a\begin{vmatrix} e &amp; f \newline h &amp; k \end{vmatrix} -b\begin{vmatrix} d &amp; f \newline g &amp; k \end{vmatrix} +c\begin{vmatrix} d &amp; e \newline g &amp; h \end{vmatrix}$……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/matrix/">Read More</a></p>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/linear-regression/" title="Linear Regression" >Linear Regression</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Basic Idea Fit a line to a bunch of points.
Example Without extra information, we will predict the mean 2.47.
Average squared error = $\mathbb{E} [(studentGPA - predictedGPA)^2]$ = Variance
If we have SAT scores, then we can fit a line.
Now if we predict based on this line, the MSE drops to 0.43.
This is a regression problem with:
 Predictor variable: SAT score Response variable: College GPA  Formula For $\mathbb{R}$ $$y = ax + b$$……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/linear-regression/">Read More</a></p>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/bayes-optimal-classifier/" title="Bayes Optimal Classifier" >Bayes Optimal Classifier</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Background Marginal Distribution
Three ways to sample from P
 Draw (x,y) Draw y according to its marginal distribution, then x according to the conditional distribution of x | y Draw X according to its marginal distribution, then Y according to the conditional distribution of y | x  Define:
$\mu$: distribution on $X$
$\eta$: conditional distribution y|x
Classifier Normal Classifier
$h : x \rightarrow y$
$R(h) = Pr_{(x,y) \in p} (h(x) \neq y)$, where R = risk……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/bayes-optimal-classifier/">Read More</a></p>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/marginal-distribution/" title="Marginal Distribution" >Marginal Distribution</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/mathematic">mathematic</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Marginal Distribution: It&rsquo;s a function that gives the probability based on only subset of the variables.1. For example,
Or in mathematical way, for discrete
$$Pr(X = x) = \sum_y Pr(X = x, Y = y) = \sum_y Pr(X = x | Y = y) Pr(Y = y)$$
and for continuous
$$p_X(x) = \int_y p_{X,Y}(x,y) dy = \int_y p_{X|Y}(x|y)p_Y(y) dy$$
and it can also be written as Expected Vaue
$$p_X(x) = \int_y p_{X|Y} (x|y) p_Y(y) dy = \mathbb{E}_Y[p_{X|Y} (x|y)]$$……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/marginal-distribution/">Read More</a></p>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/lp-norm/" title="lp norm" >lp norm</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Families of Distance Function $l_p$ norm The most common one is $l_2$ norm (Euclidean distance):
$$||x - z||_2 = \sqrt{\sum_{i=1}^{m}(x_i - z_i)^2}$$
Notes: sometime 2 is dropped.
For $p \geq 1$, the $l_p$ distance:
$$||x - z||_p = (\sum_{i=1}^{m}(x_i - z_i)^p)^{1/p}$$
Special case:
$l_1$ distance: $$||x - z||_1 = \sum_{i=1}^{m}|x_i - z_i|$$
$l_\infty$ distance:
$$||x - z||_1 = max_i |x_i - z_i|$$
Metric space Let $X$ be the space that data lie.……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/lp-norm/">Read More</a></p>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/nearest-neighbor-classification/" title="Nearest Neighbor Classification" >Nearest Neighbor Classification</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Nearest Neighbor Classification Procedures  Assemble a data set (training set)  How to classify a new image x?  find its closest neighbor y, and label it the same   Notes:
 training set of 60000 images test set of 10000 images  How do we determine if two data (images) are closest? With 28 x 28 image, we can strech it to become a vector of 784.……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/nearest-neighbor-classification/">Read More</a></p>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/fast-fourtier-transform/" title="Fast Fourtier Transform" >Fast Fourtier Transform</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/30
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/algorithm">algorithm</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Problem Given two vectors $a = (a_1, a_2, a_{n-1})$ and $b = (a_1, b_2, b_{n-1})$.
The convolution of a * b is a vector with 2n - 1 coordinates, where coordinate k is $\sum_{(i,j):i+j=k|i,j &lt; n} a_ib_j$, which is can be written as
$$a ∗ b = (a_0b_0, a_0b_1 + a_1b_0, a_0b_2 + a_1b_1 + a_2b_0, &hellip; , a_{n−2}b_{n−1} + a_{n−1}b_{n−2}, a_{n−1}b_{n−1})$$
Or an n x n table, whose (i, j) entry is $a_ib_j$……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/fast-fourtier-transform/">Read More</a></p>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/integer-multiplication/" title="Integer Multiplication" >Integer Multiplication</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/30
                            </date>
                            
                            <div class="post-meta">
                                <span>|</span>
                                
                                <span class="meta-category"><a href="https://keithzeng.github.io/categories/algorithm">algorithm</a></span>
                                
                            </div>
                            
                            <div class="post-content">
                                Problem Wiki Explanation
Algorithm Let&rsquo;s say we define $x = x_1 2^{n/2} + x_0$, then xy become \begin{align} xy &amp;= (x_1 2^{n/2} + x_0)(y_1 2^{n/2} + y_0) \newline &amp;= x_1 y_1 2^n + (x_1 y_0 + x_0 y_1)2^{n/2} + x_0 y_0 \end{align}
So we have $$T(n) \leq 4T(n/2) + cn$$ But this is essentially $$T(n) \leq O(n^{\log_2 q}) = O(n^2)$$
However, we can reduce the time by observing that $(x_1 + x_0)(y_1 + y_0) = x_1y_1 + x_1y_0 + x_0y_1 + x_0y_0$.……
                            </div>
                            <p class="readmore"><a href="https://keithzeng.github.io/posts/integer-multiplication/">Read More</a></p>
                        </article>
                    

                    


<ol class="page-navigator">
    

    
    <li  class="current">
        <a href="https://keithzeng.github.io/">1</a>
    </li>
    
    <li >
        <a href="https://keithzeng.github.io/page/2/">2</a>
    </li>
    

    
    <li class="next">
        <a href="https://keithzeng.github.io/page/2/">Next</a>
    </li>
    
</ol>



                </div>
            </div>

            <div id="secondary">
    <section class="widget">
        <form id="search" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://keithzeng.github.io">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">Most Recents</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://keithzeng.github.io/posts/convex-optimization/" title="Convex Optimization">Convex Optimization</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/logistic-regression/" title="Logistic Regression">Logistic Regression</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/matrix/" title="Matrix">Matrix</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/linear-regression/" title="Linear Regression">Linear Regression</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/bayes-optimal-classifier/" title="Bayes Optimal Classifier">Bayes Optimal Classifier</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/marginal-distribution/" title="Marginal Distribution">Marginal Distribution</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/lp-norm/" title="lp norm">lp norm</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/nearest-neighbor-classification/" title="Nearest Neighbor Classification">Nearest Neighbor Classification</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/fast-fourtier-transform/" title="Fast Fourtier Transform">Fast Fourtier Transform</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/integer-multiplication/" title="Integer Multiplication">Integer Multiplication</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">Categories</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://keithzeng.github.io/categories/algorithm/">algorithm(6)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/machine-learning/">machine-learning(7)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/mathematic/">mathematic(4)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/other/">other(3)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">Series</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://keithzeng.github.io/series/divide-and-conquer/">divide-and-conquer(5)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/greedy/">greedy(1)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/matrix/">matrix(1)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/other/">other(3)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/probability/">probability(1)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/statistical-learning/">statistical-learning(9)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">Tags</h3>
<div class="tagcloud">
    
    <a href="https://keithzeng.github.io/tags/bayes/">bayes</a>
    
    <a href="https://keithzeng.github.io/tags/confidence-interval/">confidence-interval</a>
    
    <a href="https://keithzeng.github.io/tags/convexity/">convexity</a>
    
    <a href="https://keithzeng.github.io/tags/cse202/">cse202</a>
    
    <a href="https://keithzeng.github.io/tags/cse250b/">cse250b</a>
    
    <a href="https://keithzeng.github.io/tags/determinant/">determinant</a>
    
    <a href="https://keithzeng.github.io/tags/distance/">distance</a>
    
    <a href="https://keithzeng.github.io/tags/distribution/">distribution</a>
    
    <a href="https://keithzeng.github.io/tags/knn/">knn</a>
    
    <a href="https://keithzeng.github.io/tags/logistic/">logistic</a>
    
    <a href="https://keithzeng.github.io/tags/lpnorm/">lpnorm</a>
    
    <a href="https://keithzeng.github.io/tags/metric/">metric</a>
    
    <a href="https://keithzeng.github.io/tags/mnist/">mnist</a>
    
    <a href="https://keithzeng.github.io/tags/notes/">notes</a>
    
    <a href="https://keithzeng.github.io/tags/other/">other</a>
    
    <a href="https://keithzeng.github.io/tags/probability/">probability</a>
    
    <a href="https://keithzeng.github.io/tags/rank/">rank</a>
    
    <a href="https://keithzeng.github.io/tags/regression/">regression</a>
    
    <a href="https://keithzeng.github.io/tags/statistic/">statistic</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">Other</h3>
        <ul class="widget-list">
            <li><a href="https://keithzeng.github.io/index.xml">RSS</a></li>
        </ul>
    </section>
</div>
        </div>
    </div>
</div>
<footer id="footer">
    <div class="container">
        &copy; 2019 <a href="https://keithzeng.github.io">k317h By k317h</a>.
    </div>
</footer>

<script type="text/javascript">
    
    (function(){
        $("pre code").parent().addClass("line-numbers")
    }())

    window.MathJax = {
        tex2jax: {
            inlineMath: [ ['$','$'] ],
            processEscapes: true
        }
    };
</script>
<script type="text/javascript" src="/js/prism.js" async="true"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src="/js/totop.js?v=0.0.0" async=""></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-133234541-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>





</body>
</html>
