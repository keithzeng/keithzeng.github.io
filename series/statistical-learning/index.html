<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="generator" content="Hugo 0.58.3" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>statistical learning | k317h</title>
    <meta property="og:title" content="statistical learning - k317h">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="Java,Web,Software">
    <meta name="description" content="statistical learning">
        
    <meta name="author" content="k317h">
    <meta property="og:url" content="https://keithzeng.github.io/series/statistical-learning/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href="/css/normalize.css">
    
    <link rel="stylesheet" href="/css/style.css">
    <link rel="alternate" type="application/rss+xml+xml" href="https://keithzeng.github.io/series/statistical-learning/index.xml" title="k317h" />
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>

    


    
    
</head>


<body>
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://keithzeng.github.io">
                        k317h
                    </a>
                
                <p class="description">A Blog to Record My Progress...</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://keithzeng.github.io">Main</a>
                    
                    <a  href="https://keithzeng.github.io/projects/" title="Projects">Projects</a>
                    
                    <a  href="https://keithzeng.github.io/archives/" title="Archives">Archives</a>
                    
                    <a  href="https://keithzeng.github.io/about/" title="About">About</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>


<div id="body">
    <div class="container">
        <div class="col-group">

            <div class="col-8" id="main">
                <div class="res-cons">
                    <h3 class="archive-title">
                        Articles in
                        <span class="keyword">statistical learning</span>
                        series
                    </h3>

                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/constrained-optimization/">Constrained Optimization</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/2/14
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Constrained Optimization $$\min_{x \in R^n} f(x)$$
subject to: $$c_i (x) = 0, i \in E \text{(equality constraints)}$$ $$c_i (x) \geq 0, i \in I \text{(inequality constraints)}$$
Feasible Set $\Omega = { x_i | c_i(x) = 0, i \in E \text{ and } c_i(x) \geq 0, i \in I}$.
Case 1 $\min_{x \in R^n} f(x)$ subject to $c_1 (x) = 0$
x is local minimum if x + s $\notin \Omega$ or f(x+s) $\geq$ f(x).……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/constrained-optimization/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/gradient-descent/">Gradient Descent</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/2/7
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Gradient Descent A simple algorithm to go &ldquo;downward&rdquo; against the gradient of the function. Algebrically: $$w_{t+1} = w_t - \eta \nabla f(w_t)$$ where $\eta$ is called learning rate or step size.
Step Size  $\eta$ too small, slow convergence $\eta$ too large, solution will bounce around  In practice:
 Set $\eta$ to be a smalle constant Backtracking line search (work when $\nabla f$ is continuous)  Parameter $\bar{\alpha}, c \in (0,1), \rho \in (0,1)$.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/gradient-descent/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/convex-optimization/">Convex Optimization</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/2/7
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Gradient &amp;&amp; Hessian The gradient of a f, d x 1, can be represented as follow $$ \nabla f(x) = \begin{bmatrix} \frac {\partial f(x)} {\partial x_1} \newline &hellip;\newline \frac {\partial f(x)} {\partial x_d} \end{bmatrix} $$
and the Hessian, d x d, can be represented as
$$ \nabla^2 f(x) = \begin{bmatrix} \frac {\partial^2 f(x)} {\partial x_1^2} &amp; \frac {\partial^2 f(x)} {\partial x_1x_2} &amp; \frac {\partial^2 f(x)} {\partial x_1x_d} \newline &hellip; &amp; &hellip; &amp; &hellip;\newline \frac {\partial^2 f(x)} {\partial x_d^2} &amp; \frac {\partial^2 f(x)} {\partial x_dx_2} &amp; \frac {\partial^2 f(x)} {\partial x_dx_d} \newline \end{bmatrix} $$……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/convex-optimization/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/logistic-regression/">Logistic Regression</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/2/1
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Uncertainty in Prediction Related to Linear Regression.
The available features x do not contain enough information to perfectly predict y, such as
 x = medical record for patients at risk for a disease y = will he contact disease in next 5 years  Model We still going to use linear model for conditional probability estmation
$$w_1x_1 + w_2x_2 + &hellip; + w_dx_d + b = w \cdot x + b$$……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/logistic-regression/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/linear-regression/">Linear Regression</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Basic Idea Fit a line to a bunch of points.
Example Without extra information, we will predict the mean 2.47.
Average squared error = $\mathbb{E} [(studentGPA - predictedGPA)^2]$ = Variance
If we have SAT scores, then we can fit a line.
Now if we predict based on this line, the MSE drops to 0.43.
This is a regression problem with:
 Predictor variable: SAT score Response variable: College GPA  Formula For $\mathbb{R}$ $$y = ax + b$$……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/linear-regression/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/bayes-optimal-classifier/">Bayes Optimal Classifier</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Background Marginal Distribution
Three ways to sample from P
 Draw (x,y) Draw y according to its marginal distribution, then x according to the conditional distribution of x | y Draw X according to its marginal distribution, then Y according to the conditional distribution of y | x  Define:
$\mu$: distribution on $X$
$\eta$: conditional distribution y|x
Classifier Normal Classifier
$h : x \rightarrow y$
$R(h) = Pr_{(x,y) \in p} (h(x) \neq y)$, where R = risk……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/bayes-optimal-classifier/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/lp-norm/">lp norm</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Families of Distance Function $l_p$ norm The most common one is $l_2$ norm (Euclidean distance):
$$||x - z||_2 = \sqrt{\sum_{i=1}^{m}(x_i - z_i)^2}$$
Notes: sometime 2 is dropped.
For $p \geq 1$, the $l_p$ distance:
$$||x - z||_p = (\sum_{i=1}^{m}(x_i - z_i)^p)^{1/p}$$
Special case:
$l_1$ distance: $$||x - z||_1 = \sum_{i=1}^{m}|x_i - z_i|$$
$l_\infty$ distance:
$$||x - z||_1 = max_i |x_i - z_i|$$
Metric space Let $X$ be the space that data lie.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/lp-norm/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/nearest-neighbor-classification/">Nearest Neighbor Classification</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Nearest Neighbor Classification Procedures  Assemble a data set (training set)  How to classify a new image x?  find its closest neighbor y, and label it the same   Notes:
 training set of 60000 images test set of 10000 images  How do we determine if two data (images) are closest? With 28 x 28 image, we can strech it to become a vector of 784.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/nearest-neighbor-classification/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/margin-error/">Margin of Error</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/27
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/mathematic">mathematic</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Z-Score vs T-Score Z-Score Link
Z-Score&rsquo;s formula $$z = \frac{X - \mu}{\sigma}$$ where X = sample mean, $\mu$ = population means, $\sigma$ = population standard deviation.
Also, we use Z Score when sample size &gt;= 30 or we know the population&rsquo;s mean dna SD.
Z Table
T-Score T-Score T-Score&rsquo;s formula $$T = \frac{X - \mu}{s/ \sqrt{n}}$$ where X = sample mean, $\mu$ = population mean, s = sample standard deviation, and n = sample size.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/margin-error/">Read More</a></p>
                            </div>
                        </article>
                    

                    


<ol class="page-navigator">
    

    
    <li  class="current">
        <a href="https://keithzeng.github.io/series/statistical-learning/">1</a>
    </li>
    
    <li >
        <a href="https://keithzeng.github.io/series/statistical-learning/page/2/">2</a>
    </li>
    

    
    <li class="next">
        <a href="https://keithzeng.github.io/series/statistical-learning/page/2/">Next</a>
    </li>
    
</ol>



                </div>
            </div>

            <div id="secondary">
    <section class="widget">
        <form id="search" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://keithzeng.github.io">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">Most Recents</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://keithzeng.github.io/posts/network-flow/" title="Network Flow">Network Flow</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/constrained-optimization/" title="Constrained Optimization">Constrained Optimization</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/full-stack-skill/" title="Full Stack Skill">Full Stack Skill</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/sequence-alignment-revisited/" title="Sequence Alignment Revisited">Sequence Alignment Revisited</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/sequence-alignment/" title="Sequence Alignment">Sequence Alignment</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/rna-secondary-structure/" title="RNA Secondary Structure">RNA Secondary Structure</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/knapsack/" title="Knapsack">Knapsack</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/segmented-least-square/" title="Segmented Least Square">Segmented Least Square</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/weighted-interval-scheduling/" title="Weighted Interval Scheduling">Weighted Interval Scheduling</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/gradient-descent/" title="Gradient Descent">Gradient Descent</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">Categories</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://keithzeng.github.io/categories/algorithm/">algorithm(17)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/machine-learning/">machine-learning(11)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/mathematic/">mathematic(5)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/other/">other(4)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/software-engineering/">software-engineering(1)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">Series</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://keithzeng.github.io/series/divide-and-conquer/">divide-and-conquer(6)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/dynamic-programing/">dynamic-programing(7)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/full-stack/">full-stack(1)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/greedy/">greedy(2)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/matrix/">matrix(2)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/network-flow/">network-flow(1)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/np/">np(1)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/other/">other(4)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/probability/">probability(1)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/statistical-learning/">statistical-learning(13)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">Tags</h3>
<div class="tagcloud">
    
    <a href="https://keithzeng.github.io/tags/back-end/">back-end</a>
    
    <a href="https://keithzeng.github.io/tags/bayes/">bayes</a>
    
    <a href="https://keithzeng.github.io/tags/confidence-interval/">confidence-interval</a>
    
    <a href="https://keithzeng.github.io/tags/convexity/">convexity</a>
    
    <a href="https://keithzeng.github.io/tags/coordinate-descent/">coordinate-descent</a>
    
    <a href="https://keithzeng.github.io/tags/cse202/">cse202</a>
    
    <a href="https://keithzeng.github.io/tags/cse250b/">cse250b</a>
    
    <a href="https://keithzeng.github.io/tags/determinant/">determinant</a>
    
    <a href="https://keithzeng.github.io/tags/distance/">distance</a>
    
    <a href="https://keithzeng.github.io/tags/distribution/">distribution</a>
    
    <a href="https://keithzeng.github.io/tags/divide-and-conquer/">divide-and-conquer</a>
    
    <a href="https://keithzeng.github.io/tags/dp/">dp</a>
    
    <a href="https://keithzeng.github.io/tags/front-end/">front-end</a>
    
    <a href="https://keithzeng.github.io/tags/gradient-descent/">gradient-descent</a>
    
    <a href="https://keithzeng.github.io/tags/hw/">hw</a>
    
    <a href="https://keithzeng.github.io/tags/knn/">knn</a>
    
    <a href="https://keithzeng.github.io/tags/logistic/">logistic</a>
    
    <a href="https://keithzeng.github.io/tags/lpnorm/">lpnorm</a>
    
    <a href="https://keithzeng.github.io/tags/metric/">metric</a>
    
    <a href="https://keithzeng.github.io/tags/mnist/">mnist</a>
    
    <a href="https://keithzeng.github.io/tags/network-flow/">network-flow</a>
    
    <a href="https://keithzeng.github.io/tags/notes/">notes</a>
    
    <a href="https://keithzeng.github.io/tags/optimization/">optimization</a>
    
    <a href="https://keithzeng.github.io/tags/other/">other</a>
    
    <a href="https://keithzeng.github.io/tags/probability/">probability</a>
    
    <a href="https://keithzeng.github.io/tags/project/">project</a>
    
    <a href="https://keithzeng.github.io/tags/psd/">psd</a>
    
    <a href="https://keithzeng.github.io/tags/rank/">rank</a>
    
    <a href="https://keithzeng.github.io/tags/regression/">regression</a>
    
    <a href="https://keithzeng.github.io/tags/statistic/">statistic</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">Other</h3>
        <ul class="widget-list">
            <li><a href="https://keithzeng.github.io/index.xml">RSS</a></li>
        </ul>
    </section>
</div>
        </div>
    </div>
</div>
<footer id="footer">
    <div class="container">
        &copy; 2019 <a href="https://keithzeng.github.io">k317h By k317h</a>.
    </div>
</footer>

<script type="text/javascript">
    
    (function(){
        $("pre code").parent().addClass("line-numbers")
    }())

    window.MathJax = {
        tex2jax: {
            inlineMath: [ ['$','$'] ],
            processEscapes: true,
        },
        TeX: { equationNumbers: { autoNumber: "AMS" } }
    };
</script>
<script type="text/javascript" src="/js/prism.js" async="true"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src="/js/totop.js?v=0.0.0" async=""></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-133234541-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
