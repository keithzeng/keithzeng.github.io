<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>statistical learning on k317h</title>
    <link>https://keithzeng.github.io/series/statistical-learning/</link>
    <description>Recent content in statistical learning on k317h</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 18 Feb 2019 10:37:54 -0800</lastBuildDate>
    
	<atom:link href="https://keithzeng.github.io/series/statistical-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>CSE250 Proj2</title>
      <link>https://keithzeng.github.io/hws/cse250-proj2/</link>
      <pubDate>Mon, 18 Feb 2019 10:37:54 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/hws/cse250-proj2/</guid>
      <description>Coordinate Descent (a) In this project I compared different methods using different approaches. Besides the random coordinate descent (RCD), I implemented two ways to choose the coordinate: cyclic coordinate descent method(CCD) and greatest coordinate descent method (GCD). CCD updates the coordinate in cycle and GCD update the coordinate with greatest derivative.1
(b) For every iteration, the coordinate, i, being picked will be updated with below methods.
Method 1 (Minimize Loss Function)</description>
    </item>
    
    <item>
      <title>Constrained Optimization</title>
      <link>https://keithzeng.github.io/posts/constrained-optimization/</link>
      <pubDate>Thu, 14 Feb 2019 15:43:04 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/constrained-optimization/</guid>
      <description>Constrained Optimization $$\min_{x \in R^n} f(x)$$
subject to: $$c_i (x) = 0, i \in E \text{(equality constraints)}$$ $$c_i (x) \geq 0, i \in I \text{(inequality constraints)}$$
Feasible Set $\Omega = { x_i | c_i(x) = 0, i \in E \text{ and } c_i(x) \geq 0, i \in I}$.
Case 1 $\min_{x \in R^n} f(x)$ subject to $c_1 (x) = 0$
x is local minimum if x + s $\notin \Omega$ or f(x+s) $\geq$ f(x).</description>
    </item>
    
    <item>
      <title>Gradient Descent</title>
      <link>https://keithzeng.github.io/posts/gradient-descent/</link>
      <pubDate>Thu, 07 Feb 2019 22:21:16 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/gradient-descent/</guid>
      <description>Gradient Descent A simple algorithm to go &amp;ldquo;downward&amp;rdquo; against the gradient of the function. Algebrically: $$w_{t+1} = w_t - \eta \nabla f(w_t)$$ where $\eta$ is called learning rate or step size.
Step Size  $\eta$ too small, slow convergence $\eta$ too large, solution will bounce around  In practice:
 Set $\eta$ to be a smalle constant Backtracking line search (work when $\nabla f$ is continuous)  Parameter $\bar{\alpha}, c \in (0,1), \rho \in (0,1)$.</description>
    </item>
    
    <item>
      <title>Convex Optimization</title>
      <link>https://keithzeng.github.io/posts/convex-optimization/</link>
      <pubDate>Thu, 07 Feb 2019 22:15:35 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/convex-optimization/</guid>
      <description>Gradient &amp;amp;&amp;amp; Hessian The gradient of a f, d x 1, can be represented as follow $$ \nabla f(x) = \begin{bmatrix} \frac {\partial f(x)} {\partial x_1} \newline &amp;hellip;\newline \frac {\partial f(x)} {\partial x_d} \end{bmatrix} $$
and the Hessian, d x d, can be represented as
$$ \nabla^2 f(x) = \begin{bmatrix} \frac {\partial^2 f(x)} {\partial x_1^2} &amp;amp; \frac {\partial^2 f(x)} {\partial x_1x_2} &amp;amp; \frac {\partial^2 f(x)} {\partial x_1x_d} \newline &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip;\newline \frac {\partial^2 f(x)} {\partial x_d^2} &amp;amp; \frac {\partial^2 f(x)} {\partial x_dx_2} &amp;amp; \frac {\partial^2 f(x)} {\partial x_dx_d} \newline \end{bmatrix} $$</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>https://keithzeng.github.io/posts/logistic-regression/</link>
      <pubDate>Fri, 01 Feb 2019 14:39:49 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/logistic-regression/</guid>
      <description>Uncertainty in Prediction Related to Linear Regression.
The available features x do not contain enough information to perfectly predict y, such as
 x = medical record for patients at risk for a disease y = will he contact disease in next 5 years  Model We still going to use linear model for conditional probability estmation
$$w_1x_1 + w_2x_2 + &amp;hellip; + w_dx_d + b = w \cdot x + b$$</description>
    </item>
    
    <item>
      <title>Linear Regression</title>
      <link>https://keithzeng.github.io/posts/linear-regression/</link>
      <pubDate>Thu, 31 Jan 2019 22:30:23 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/linear-regression/</guid>
      <description>Basic Idea Fit a line to a bunch of points.
Example Without extra information, we will predict the mean 2.47.
Average squared error = $\mathbb{E} [(studentGPA - predictedGPA)^2]$ = Variance
If we have SAT scores, then we can fit a line.
Now if we predict based on this line, the MSE drops to 0.43.
This is a regression problem with:
 Predictor variable: SAT score Response variable: College GPA  Formula For $\mathbb{R}$ $$y = ax + b$$</description>
    </item>
    
    <item>
      <title>Bayes Optimal Classifier</title>
      <link>https://keithzeng.github.io/posts/bayes-optimal-classifier/</link>
      <pubDate>Thu, 31 Jan 2019 18:00:14 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/bayes-optimal-classifier/</guid>
      <description>Background Marginal Distribution
Three ways to sample from P
 Draw (x,y) Draw y according to its marginal distribution, then x according to the conditional distribution of x | y Draw X according to its marginal distribution, then Y according to the conditional distribution of y | x  Define:
$\mu$: distribution on $X$
$\eta$: conditional distribution y|x
Classifier Normal Classifier
$h : x \rightarrow y$
$R(h) = Pr_{(x,y) \in p} (h(x) \neq y)$, where R = risk</description>
    </item>
    
    <item>
      <title>lp norm</title>
      <link>https://keithzeng.github.io/posts/lp-norm/</link>
      <pubDate>Thu, 31 Jan 2019 17:02:35 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/lp-norm/</guid>
      <description>Families of Distance Function $l_p$ norm The most common one is $l_2$ norm (Euclidean distance):
$$||x - z||_2 = \sqrt{\sum_{i=1}^{m}(x_i - z_i)^2}$$
Notes: sometime 2 is dropped.
For $p \geq 1$, the $l_p$ distance:
$$||x - z||_p = (\sum_{i=1}^{m}(x_i - z_i)^p)^{1/p}$$
Special case:
$l_1$ distance: $$||x - z||_1 = \sum_{i=1}^{m}|x_i - z_i|$$
$l_\infty$ distance:
$$||x - z||_1 = max_i |x_i - z_i|$$
Metric space Let $X$ be the space that data lie.</description>
    </item>
    
    <item>
      <title>Nearest Neighbor Classification</title>
      <link>https://keithzeng.github.io/posts/nearest-neighbor-classification/</link>
      <pubDate>Thu, 31 Jan 2019 16:08:27 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/nearest-neighbor-classification/</guid>
      <description>Nearest Neighbor Classification Procedures  Assemble a data set (training set)  How to classify a new image x?  find its closest neighbor y, and label it the same   Notes:
 training set of 60000 images test set of 10000 images  How do we determine if two data (images) are closest? With 28 x 28 image, we can strech it to become a vector of 784.</description>
    </item>
    
    <item>
      <title>Margin of Error</title>
      <link>https://keithzeng.github.io/posts/margin-error/</link>
      <pubDate>Sun, 27 Jan 2019 22:33:16 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/margin-error/</guid>
      <description>Z-Score vs T-Score Z-Score Link
Z-Score&amp;rsquo;s formula $$z = \frac{X - \mu}{\sigma}$$ where X = sample mean, $\mu$ = population means, $\sigma$ = population standard deviation.
Also, we use Z Score when sample size &amp;gt;= 30 or we know the population&amp;rsquo;s mean dna SD.
Z Table
T-Score T-Score T-Score&amp;rsquo;s formula $$T = \frac{X - \mu}{s/ \sqrt{n}}$$ where X = sample mean, $\mu$ = population mean, s = sample standard deviation, and n = sample size.</description>
    </item>
    
    <item>
      <title>Prototype Selection</title>
      <link>https://keithzeng.github.io/posts/prototype-selection/</link>
      <pubDate>Sun, 27 Jan 2019 20:25:22 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/prototype-selection/</guid>
      <description>Backgrond kNN prototype selection Summary List
There are couple drawbacks for KNN
 high storage for data computation for decision boundary intolerance to noise  There are couple methods address above issue
 better similarity metric or better distance function k-d trees or R-trees as storage reduction technique (prototype selection)  Prototype Selection 1. edition method - remove noise 1. condensation method - remove superfluous dataset 1. hybrid method - achive elimination of noise and superfluous at the same time</description>
    </item>
    
    <item>
      <title>CSE250 Proj1</title>
      <link>https://keithzeng.github.io/hws/cse250-proj1/</link>
      <pubDate>Sun, 27 Jan 2019 16:22:07 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/hws/cse250-proj1/</guid>
      <description>Project 1
1. Prototype Selection Divide data into ${S_1, S_2, &amp;hellip;, S_c}$, where c = number of labels. For each dataset $S_i$, I select M/c points as new training set for that label, which are the centroids by running k-means clustering algorithm.
My idea was to capture as many distinct types in for each label and meanwhile reduce the noise by selecting only the center of the each type.</description>
    </item>
    
    <item>
      <title>Probability</title>
      <link>https://keithzeng.github.io/posts/probability/</link>
      <pubDate>Thu, 24 Jan 2019 22:27:30 -0800</pubDate>
      
      <guid>https://keithzeng.github.io/posts/probability/</guid>
      <description>Discrete Random Variables A random variable is a number whose value depends upon the outcome of a random experiement. Such as tossing a coin 10 times and let X be the number of Head.
A discrete random variable X has finitely countable values $x_i = 1, 2&amp;hellip;$ and $p(x_i) = P(X = x_i)$ is called probability mass function.
Probability mass functions has following properties:
 For all i, $p(x_i) &amp;gt; 0$ For any interval $P(X \in B) = \sum_{x_i \in B}p(x_i)$ $\sum_{i}p(x_i) = 1$  There are many types of discrete random variable</description>
    </item>
    
  </channel>
</rss>