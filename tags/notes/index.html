<!doctype html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="generator" content="Hugo 0.53" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Notes | k317h</title>
    <meta property="og:title" content="Notes - k317h">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="Java,Web,Software">
    <meta name="description" content="Notes">
        
    <meta name="author" content="k317h">
    <meta property="og:url" content="https://keithzeng.github.io/tags/notes/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href="/css/normalize.css">
    
    <link rel="stylesheet" href="/css/style.css">
    <link rel="alternate" type="application/rss+xml+xml" href="https://keithzeng.github.io/tags/notes/index.xml" title="k317h" />
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>

    


    
    
</head>


<body>
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://keithzeng.github.io">
                        k317h
                    </a>
                
                <p class="description">A Blog to Record My Progress...</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="https://keithzeng.github.io">Main</a>
                    
                    <a  href="https://keithzeng.github.io/books/" title="Books">Books</a>
                    
                    <a  href="https://keithzeng.github.io/archives/" title="Archives">Archives</a>
                    
                    <a  href="https://keithzeng.github.io/about/" title="About">About</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>


<div id="body">
    <div class="container">
        <div class="col-group">

            <div class="col-8" id="main">
                <div class="res-cons">
                    <h3 class="archive-title">
                        Articles in
                        <span class="keyword">notes</span>
                        tag
                    </h3>

                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/linear-regression/">Linear Regression</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Basic Idea Fit a line to a bunch of points.
Example Without extra information, we will predict the mean 2.47.
Average squared error = $\mathbb{E} [(studentGPA - predictedGPA)^2]$ = Variance
If we have SAT scores, then we can fit a line.
Now if we predict based on this line, the MSE drops to 0.43.
This is a regression problem with:
 Predictor variable: SAT score Response variable: College GPA  Formula For $\mathbb{R}$ $$y = ax + b$$……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/linear-regression/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/bayes-optimal-classifier/">Bayes Optimal Classifier</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Background Marginal Distribution
Three ways to sample from P
 Draw (x,y) Draw y according to its marginal distribution, then x according to the conditional distribution of x | y Draw X according to its marginal distribution, then Y according to the conditional distribution of y | x  Define:
$\mu$: distribution on $X$
$\eta$: conditional distribution y|x
Classifier Normal Classifier
$h : x \rightarrow y$
$R(h) = Pr_{(x,y) \in p} (h(x) \neq y)$, where R = risk……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/bayes-optimal-classifier/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/lp-norm/">lp norm</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Families of Distance Function $l_p$ norm The most common one is $l_2$ norm (Euclidean distance):
$$||x - z||_2 = \sqrt{\sum_{i=1}^{m}(x_i - z_i)^2}$$
Notes: sometime 2 is dropped.
For $p \geq 1$, the $l_p$ distance:
$$||x - z||_p = (\sum_{i=1}^{m}(x_i - z_i)^p)^{1/p}$$
Special case:
$l_1$ distance: $$||x - z||_1 = \sum_{i=1}^{m}|x_i - z_i|$$
$l_\infty$ distance:
$$||x - z||_1 = max_i |x_i - z_i|$$
Metric space Let $X$ be the space that data lie.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/lp-norm/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/nearest-neighbor-classification/">Nearest Neighbor Classification</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/31
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/machine-learning">machine learning</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Nearest Neighbor Classification Procedures  Assemble a data set (training set)  How to classify a new image x?  find its closest neighbor y, and label it the same   Notes:
 training set of 60000 images test set of 10000 images  How do we determine if two data (images) are closest? With 28 x 28 image, we can strech it to become a vector of 784.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/nearest-neighbor-classification/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/fast-fourtier-transform/">Fast Fourtier Transform</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/30
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/algorithm">algorithm</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Problem Given two vectors $a = (a_1, a_2, a_{n-1})$ and $b = (a_1, b_2, b_{n-1})$.
The convolution of a * b is a vector with 2n - 1 coordinates, where coordinate k is $\sum_{(i,j):i+j=k|i,j &lt; n} a_ib_j$, which is can be written as
$$a ∗ b = (a_0b_0, a_0b_1 + a_1b_0, a_0b_2 + a_1b_1 + a_2b_0, &hellip; , a_{n−2}b_{n−1} + a_{n−1}b_{n−2}, a_{n−1}b_{n−1})$$
Or an n x n table, whose (i, j) entry is $a_ib_j$……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/fast-fourtier-transform/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/integer-multiplication/">Integer Multiplication</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/30
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/algorithm">algorithm</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Problem Wiki Explanation
Algorithm Let&rsquo;s say we define $x = x_1 2^{n/2} + x_0$, then xy become \begin{align} xy &amp;= (x_1 2^{n/2} + x_0)(y_1 2^{n/2} + y_0) \newline &amp;= x_1 y_1 2^n + (x_1 y_0 + x_0 y_1)2^{n/2} + x_0 y_0 \end{align}
So we have $$T(n) \leq 4T(n/2) + cn$$ But this is essentially $$T(n) \leq O(n^{\log_2 q}) = O(n^2)$$
However, we can reduce the time by observing that $(x_1 + x_0)(y_1 + y_0) = x_1y_1 + x_1y_0 + x_0y_1 + x_0y_0$.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/integer-multiplication/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/closest-point/">Closest Point</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/29
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/algorithm">algorithm</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Problem Given n points in the plane, find the pair that is closest together.
Brute force takes $O(n^2)$.
Algorithm Let&rsquo;s $d(p_i, p_j)$ = Euclidean distance.
In 1-d, we can simply sort points and compute the distance with the next point, we then have complexity of O(nlogn). In 2-d, we can&rsquo;t applied the same thing.
We will use divide and conquer. We find the closest pair in the left and closest pair in the right, and hoping to get it in linear time.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/closest-point/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/counting-inversion/">Counting Inversion</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/29
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/algorithm">algorithm</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Problem Application in ranking, also called corraborative filtering.
Comparing two rankings and decide how similar they are, or how many pairs are out of order.
To quantify this, we count the number of inversions. The inversion is defined as two indices i &lt; j that $a_i &gt; a_j$. Algorithm Brute-Force $T(n) = O(n^2)$
Modified Merge-Sort By leverage the merge process form merger-sort, we can count the number of inversion. Basically, when the element from A is appended, there is not inversion.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/counting-inversion/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/merge-sort/">Merge Sort</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/29
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/algorithm">algorithm</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Problem Sort the elements
Abstract the behavior:
1. Divide the input into two pieces of equal size O(n) 1. solve the two subproblems on these pieces separately by recursion 1. combine the two results into an overall solution O(n)
Recurrence Time Complexity q = 2 T(n) ≤ 2T(n/2) + cn
To analyze the above recurrence relation, check below image.  At level j, we have $2^j$ nodes with size $n/2^j$ Each node takes $cn/2^j$, so level j takes $cn/2^j$ x $2^j = cn$ There are logn levels, so T(n) = O(nlogn)  General Case For q &gt; 2 T(n) ≤ qT(n/2) + cn……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/merge-sort/">Read More</a></p>
                            </div>
                        </article>
                    
                        <article class="post">
                            <header>
                                <h1 class="post-title">
                                    <a href="https://keithzeng.github.io/posts/k-clustering/">K Clustering</a>
                                </h1>
                            </header>
                            <date class="post-meta meta-date">
                                2019/1/25
                            </date>
                            
                            <div class="post-meta meta-category">
                                |
                                
                                    <a href="https://keithzeng.github.io/categories/algorithm">algorithm</a>
                                
                            </div>
                            
                            <div class="post-content">
                                Problem We have set of objects $U = \{o_1, o_2, &hellip;\}$, and we want to split them into k clusters.
We also have following definition for distance function.
 $\forall_{i,j} dist(p_i, p_j) = dist(p_j, p_j)$ $\forall_{i,j} dist(p_i, p_i) = 0$ $\forall_{i,j} dist(p_i, p_j) &gt; 0$.  At the end, we should have $C = \{C_1, C_2, &hellip; C_K\}$.
Let&rsquo;s define spacing to be the minimum dist between clusters. Our goal is to find the k-clustering with maximum spacing.……
                                <p class="readmore"><a href="https://keithzeng.github.io/posts/k-clustering/">Read More</a></p>
                            </div>
                        </article>
                    

                    


<ol class="page-navigator">
    

    
    <li  class="current">
        <a href="https://keithzeng.github.io/tags/notes/">1</a>
    </li>
    
    <li >
        <a href="https://keithzeng.github.io/tags/notes/page/2/">2</a>
    </li>
    

    
    <li class="next">
        <a href="https://keithzeng.github.io/tags/notes/page/2/">Next</a>
    </li>
    
</ol>



                </div>
            </div>

            <div id="secondary">
    <section class="widget">
        <form id="search" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://keithzeng.github.io">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">Most Recents</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://keithzeng.github.io/posts/gradient-descent/" title="Gradient Descent">Gradient Descent</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/convex-optimization/" title="Convex Optimization">Convex Optimization</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/positive-semi-definite/" title="Positive Semi Definite">Positive Semi Definite</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/logistic-regression/" title="Logistic Regression">Logistic Regression</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/matrix/" title="Matrix">Matrix</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/linear-regression/" title="Linear Regression">Linear Regression</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/bayes-optimal-classifier/" title="Bayes Optimal Classifier">Bayes Optimal Classifier</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/marginal-distribution/" title="Marginal Distribution">Marginal Distribution</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/lp-norm/" title="lp norm">lp norm</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/posts/nearest-neighbor-classification/" title="Nearest Neighbor Classification">Nearest Neighbor Classification</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">Categories</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://keithzeng.github.io/categories/algorithm/">algorithm(6)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/machine-learning/">machine-learning(8)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/mathematic/">mathematic(5)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/categories/other/">other(3)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">Series</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://keithzeng.github.io/series/divide-and-conquer/">divide-and-conquer(5)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/greedy/">greedy(1)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/matrix/">matrix(2)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/other/">other(3)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/probability/">probability(1)</a>
    </li>
    
    <li>
        <a href="https://keithzeng.github.io/series/statistical-learning/">statistical-learning(10)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">Tags</h3>
<div class="tagcloud">
    
    <a href="https://keithzeng.github.io/tags/bayes/">bayes</a>
    
    <a href="https://keithzeng.github.io/tags/confidence-interval/">confidence-interval</a>
    
    <a href="https://keithzeng.github.io/tags/convexity/">convexity</a>
    
    <a href="https://keithzeng.github.io/tags/cse202/">cse202</a>
    
    <a href="https://keithzeng.github.io/tags/cse250b/">cse250b</a>
    
    <a href="https://keithzeng.github.io/tags/determinant/">determinant</a>
    
    <a href="https://keithzeng.github.io/tags/distance/">distance</a>
    
    <a href="https://keithzeng.github.io/tags/distribution/">distribution</a>
    
    <a href="https://keithzeng.github.io/tags/gradient-descent/">gradient-descent</a>
    
    <a href="https://keithzeng.github.io/tags/knn/">knn</a>
    
    <a href="https://keithzeng.github.io/tags/logistic/">logistic</a>
    
    <a href="https://keithzeng.github.io/tags/lpnorm/">lpnorm</a>
    
    <a href="https://keithzeng.github.io/tags/metric/">metric</a>
    
    <a href="https://keithzeng.github.io/tags/mnist/">mnist</a>
    
    <a href="https://keithzeng.github.io/tags/notes/">notes</a>
    
    <a href="https://keithzeng.github.io/tags/other/">other</a>
    
    <a href="https://keithzeng.github.io/tags/probability/">probability</a>
    
    <a href="https://keithzeng.github.io/tags/psd/">psd</a>
    
    <a href="https://keithzeng.github.io/tags/rank/">rank</a>
    
    <a href="https://keithzeng.github.io/tags/regression/">regression</a>
    
    <a href="https://keithzeng.github.io/tags/statistic/">statistic</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">Other</h3>
        <ul class="widget-list">
            <li><a href="https://keithzeng.github.io/index.xml">RSS</a></li>
        </ul>
    </section>
</div>
        </div>
    </div>
</div>
<footer id="footer">
    <div class="container">
        &copy; 2019 <a href="https://keithzeng.github.io">k317h By k317h</a>.
    </div>
</footer>

<script type="text/javascript">
    
    (function(){
        $("pre code").parent().addClass("line-numbers")
    }())

    window.MathJax = {
        tex2jax: {
            inlineMath: [ ['$','$'] ],
            processEscapes: true
        }
    };
</script>
<script type="text/javascript" src="/js/prism.js" async="true"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src="/js/totop.js?v=0.0.0" async=""></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-133234541-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>





</body>
</html>
